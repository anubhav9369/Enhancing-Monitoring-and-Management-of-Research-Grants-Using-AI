{
 "awd_id": "2444367",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBE-UKRI: Uncovering the causes of Look But Fail To See (LBFTS) errors",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032927238",
 "po_email": "btuller@nsf.gov",
 "po_sign_block_name": "Betty Tuller",
 "awd_eff_date": "2025-09-01",
 "awd_exp_date": "2028-08-31",
 "tot_intn_awd_amt": 199587.0,
 "awd_amount": 199587.0,
 "awd_min_amd_letter_date": "2025-08-21",
 "awd_max_amd_letter_date": "2025-08-21",
 "awd_abstract_narration": "This project seeks to understand and reduce a common and potentially dangerous type of error, where a person fails to respond to something that is right in front of them. These \u201cLook but fail to see\u201d (LBFTS) errors can be something trivial, like a typo in an email, or something much more significant, like a pedestrian in the street. To qualify as an LBFTS error, the item that is missed must be clearly visible and the observer must be \u2018expert\u2019 enough to identify the item. Thus, for example, no one would be expected to find a typo in a letter that was written in a language they do not know. Collaborating researchers in the US and the UK will create object and scene databases using real-world stimuli for use in LBFTS experiments. The goal is to identify strategies that reduce these errors, so that they can be minimized in many arenas. Of particular interest are those arenas that impact national health and security, as when a radiologist fails to see signs of cancer in a lung x-ray or a screener fails to see a weapon in carry-on luggage at the airport. \r\n\r\nThe creation of carefully curated object and scene databases will benefit many. Existing object databases are aging and often include objects that observers may not easily recognize (e.g., a dial-up modem). The experiments will identify objects that are correctly recognized by observers over 90% of the time. They will also quantify the memorability of each object and scene. Stimuli will be validated by replicating previous LBFTS experiments and the relative contributions of recognizability and memorability will be assessed. The resulting pattern of LBFTS errors with real-world stimuli should inform the types of interventions that are more likely to improve performance. For example, random errors are minimized when two sets of eyes look at a stimulus. LBFTS errors can provide information to improve artificial intelligence systems, so that AI might provide one of those sets of eyes.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jeremy",
   "pi_last_name": "Wolfe",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Jeremy M Wolfe",
   "pi_email_addr": "jwolfe@bwh.harvard.edu",
   "nsf_id": "000202279",
   "pi_start_date": "2025-08-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Brigham & Women's Hospital Inc",
  "inst_street_address": "75 FRANCIS ST",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "8572821670",
  "inst_zip_code": "021156110",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "BRIGHAM & WOMENS HOSPITAL INC",
  "org_prnt_uei_num": "KH2QJR76KMZ6",
  "org_uei_num": "QN6MS4VN7BD1"
 },
 "perf_inst": {
  "perf_inst_name": "Brigham & Women's Hospital Inc",
  "perf_str_addr": "900 Commowealth Avenue",
  "perf_city_name": "BOSTON",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021156110",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  },
  {
   "pgm_ref_code": "003Z",
   "pgm_ref_txt": "SBE-RCUK MOU"
  },
  {
   "pgm_ref_code": "075Z",
   "pgm_ref_txt": "Artificial Intelligence (AI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 199587.0
  }
 ],
 "por": null
}