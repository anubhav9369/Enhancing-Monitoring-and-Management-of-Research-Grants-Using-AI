{
 "awd_id": "2535732",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "I-Corps: Translation potential for experiential supercomputing",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032922160",
 "po_email": "rshuman@nsf.gov",
 "po_sign_block_name": "Ruth Shuman",
 "awd_eff_date": "2025-09-15",
 "awd_exp_date": "2026-08-31",
 "tot_intn_awd_amt": 50000.0,
 "awd_amount": 50000.0,
 "awd_min_amd_letter_date": "2025-08-15",
 "awd_max_amd_letter_date": "2025-08-15",
 "awd_abstract_narration": "This I-Corps project is based on the development of supercomputers for real-time, interactive problem solving and data analysis. Currently, there are significant problems in creating robust, complex, open-ended learning environments that are personalized, engaging, adaptive and scalable. Yet, such environments have great potential for the development of valuable real-world skills (e.g., creativity, leadership, and collaboration). Preliminary implementations of this type of technology exist in medical simulation and military training, and it is emerging in K-12 and higher education. In addition, supercomputers are used in on-the-job training and life-long learning experiences. This technology addresses the challenges by providing well-integrated, immersive, collaborative, and virtual/physical extended reality environments. These environments provide unparalleled tools for research collaborations, intellectual exploration, education, and creative output. They incorporate visual, audio, and physical components; artificial intelligence (AI) technologies to enhance human-human, human-agent, and human-robot social interactions; rapid prototyping and fabrication tools; and tightly coupled interactive visual, audio, and physical experiences. This solution may be applied to next-generation healthcare simulators, advanced cyberlearning environments, and smart homes for well-being and entertainment. The technology provides deep integration of virtual and physical settings and has the potential to transform the fundamental understanding of collaboration, learning, creativity, discovery and innovation.\r\n\r\nThis I-Corps project utilizes experiential learning coupled with a first-hand investigation of the industry ecosystem to assess the translation potential of experiential supercomputing. The core technology is the well-integrated fusion of interaction devices and artificial intelligence (AI) into a transformative, cohesive, and scalable instrument. The components include visual (headsets, projectors), audio (headsets, speakers, binaural), physical (spatial computing, collaborative social robots, 3D fabrication), human dynamic (wearable sensors, eye tracking), and social dynamic (co-located and remote dyadic and small team interaction) capabilities. The technology immerses users within customizable mixed-reality simulation environments by combining high-resolution visual, high-fidelity audio environments, and haptic feedback along with artificial intelligence (AI)-enabled collaborative agents and robots. The system architecture is comprised of three conceptual levels: node/field kit systems (local and distributed multimodal interaction), network systems software (latency, reliability, bandwidth), and computation (cluster/storage, data, analytic systems, services). In addition, this solution incorporates best practices from multimodal interaction research, human dynamics and social collaboration. Through AI-enabled extended reality environments that focus on the synergy of human-human, human-agent, and human-robot social interaction, experiential supercomputing may advance simulation and rapid prototyping for collocated, distributed, and collaborative teams.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Winslow",
   "pi_last_name": "Burleson",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Winslow Burleson",
   "pi_email_addr": "win@arizona.edu",
   "nsf_id": "000249639",
   "pi_start_date": "2025-08-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Arizona",
  "inst_street_address": "845 N PARK AVE RM 538",
  "inst_street_address_2": "",
  "inst_city_name": "TUCSON",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "5206266000",
  "inst_zip_code": "85721",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "AZ07",
  "org_lgl_bus_name": "UNIVERSITY OF ARIZONA",
  "org_prnt_uei_num": "",
  "org_uei_num": "ED44Y3W6P7B9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Arizona",
  "perf_str_addr": "1103 E 2nd St",
  "perf_city_name": "Tucson",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "85721",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "AZ07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802300",
   "pgm_ele_name": "I-Corps"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 50000.0
  }
 ],
 "por": null
}