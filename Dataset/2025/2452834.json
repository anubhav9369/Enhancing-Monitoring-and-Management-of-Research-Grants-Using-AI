{
 "awd_id": "2452834",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "PDaSP Track 2: Explainable Auditing of ML Models for Privacy Violations",
 "cfda_num": "47.084",
 "org_code": "15020000",
 "po_phone": "7032922251",
 "po_email": "jgeorge@nsf.gov",
 "po_sign_block_name": "Jemin George",
 "awd_eff_date": "2025-10-01",
 "awd_exp_date": "2028-09-30",
 "tot_intn_awd_amt": 400000.0,
 "awd_amount": 129032.0,
 "awd_min_amd_letter_date": "2025-08-25",
 "awd_max_amd_letter_date": "2025-08-25",
 "awd_abstract_narration": "The growing use of artificial intelligence in healthcare and medical research has created a difficult challenge: researchers need to share their computer models to advance scientific discovery, but these models can reveal private information about the patients whose data was used to create them. Organizations are often reluctant to share their computer models because of privacy risks, even though withholding these models prevents broader societal benefits from medical research. This creates a barrier to scientific collaboration that could otherwise lead to better treatments, improved public health outcomes, and medical breakthroughs. This project addresses this challenge by developing methods that allow organizations to safely share models trained on sensitive patient data without compromising individual privacy. Proposed research will result in new techniques for auditing models, certifying their privacy guarantees, and providing actionable tools to fix any identified issues. This work serves the national interest by advancing medical research and scientific discovery, enhancing national health and prosperity through improved healthcare technologies, supporting American competitiveness in artificial intelligence innovation, and enabling secure collaboration while protecting personal privacy rights.\r\n\r\nThis project develops an end-to-end framework for privacy-preserving sharing of machine learning models trained on sensitive data. Despite growing interest in sharing models rather than raw data, machine learning models remain vulnerable to privacy attacks, such as membership inference attacks, which can reveal whether an individual's data was used during training. The research activities include four technical components. First, the project will evaluate the privacy properties of shared models by subjecting them to existing and newly tailored privacy attacks, establishing a foundational understanding of their vulnerabilities. Second, the team will develop formal privacy guarantees using methods like differential privacy and establish privacy-utility tradeoffs, creating privacy certificates for machine learning models that may include legal and usage constraints. Third, the project will design explainable auditing tools and privacy patching mechanisms such as machine unlearning to help developers mitigate risks without compromising model utility. Fourth, the research will build user-friendly tools to deploy these methods, focusing on real-world applicability in healthcare and biomedical research. The project will introduce a novel privacy-risk scoring system, enabling developers and regulators to assess the privacy risks associated with a given model. Unlike existing point solutions, this comprehensive framework integrates auditing, certification, and remediation into a unified system. Results will be disseminated through tools, publications, and educational modules to support broad adoption and training.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "ITE",
 "org_div_long_name": "Innovation and Technology Ecosystems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Netanel",
   "pi_last_name": "Raviv",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Netanel Raviv",
   "pi_email_addr": "netanel.raviv@wustl.edu",
   "nsf_id": "000813321",
   "pi_start_date": "2025-08-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Yevgeniy",
   "pi_last_name": "Vorobeychik",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yevgeniy Vorobeychik",
   "pi_email_addr": "yvorobeychik@wustl.edu",
   "nsf_id": "000667978",
   "pi_start_date": "2025-08-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Washington University",
  "inst_street_address": "1 BROOKINGS DR",
  "inst_street_address_2": "",
  "inst_city_name": "SAINT LOUIS",
  "inst_state_code": "MO",
  "inst_state_name": "Missouri",
  "inst_phone_num": "3147474134",
  "inst_zip_code": "631304862",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "MO01",
  "org_lgl_bus_name": "WASHINGTON UNIVERSITY, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "L6NFUM28LQM5"
 },
 "perf_inst": {
  "perf_inst_name": "Washington University",
  "perf_str_addr": "ONE BROOKINGS DR",
  "perf_city_name": "SAINT LOUIS",
  "perf_st_code": "MO",
  "perf_st_name": "Missouri",
  "perf_zip_code": "631304899",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "MO01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "329Y00",
   "pgm_ele_name": "Privacy Preserving Data Sharin"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002627DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002728DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 129032.0
  }
 ],
 "por": null
}