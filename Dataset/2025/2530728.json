{
 "awd_id": "2530728",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NSF-BSF: RI: Small: Beyond Binary Variables: Defining, Locating, and Editing Multi-dimensional Features in Large Language Models",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032928318",
 "po_email": "vpavlovi@nsf.gov",
 "po_sign_block_name": "Vladimir Pavlovic",
 "awd_eff_date": "2025-09-01",
 "awd_exp_date": "2028-08-31",
 "tot_intn_awd_amt": 471529.0,
 "awd_amount": 471529.0,
 "awd_min_amd_letter_date": "2025-08-04",
 "awd_max_amd_letter_date": "2025-08-04",
 "awd_abstract_narration": "This project expands our understanding of what modern artificial intelligence (AI) systems know, and our ability to precisely control them. Large language models (LLMs), a type of AI, have proven useful on a wide variety of tasks, yet their internal decision-making processes remain largely a mystery. Public understanding of these systems is often based on observing their successes and failures, and there is often an assumption that LLMs represent concepts and reason with them in human-like ways. This project challenges that assumption by looking inside the models themselves. While current research has identified simple, binary concepts, or features that are either \u201con\u201d or \u201coff\u201d, most real-world concepts are more complex. They can be multi-valued, like educational attainment, which can take values high school, college, professional degree, or among others. Concepts can also exist on a continuous spectrum, like measurements of distance or time. By developing methods to find and understand these more sophisticated internal representations, this work aims to ensure that AI systems are reliable, safe, and can be controlled when needed. The first goal of this project is to move beyond binary concepts when interpreting the inner workings of AI systems, and to directly search for and characterize these multi-valued and continuous concepts. Leveraging this understanding, the second goal of this project will then be to develop tools for applying this understanding to improve AI. For example, if we can find out which parts of an LLM perform logical reasoning, we can directly update them without harming the rest of the model, or directly control them to change how the LLM reasons.\r\n\r\n\r\nTo achieve its goals, this award supports research in three main stages. First, the project will develop and test methods for discovering multi-dimensional and continuous features within LLMs. This involves using techniques like sparse dictionary learning and causal analysis to move beyond individual neurons and identify the underlying concepts they represent. Second, the project will characterize the geometric structure of these discovered features to understand how a model organizes related values. For example, are the values of an ordinal variable organized along a line, within a more complex, low-dimensional subspace, or neither? Finally, the project will leverage this structural understanding to create new techniques for precise model control. Instead of simply turning features on or off, these methods will allow for nuanced interventions, such as adjusting a concept\u2019s influence on a model\u2019s reasoning process. The developed tools and insights can enable developers and scientists to fix AI flaws without costly retraining. This democratizes AI research by enabling labs with smaller computational resources to participate in model improvement. The project will also support education by demystifying how AI systems work, fostering more practical and scientifically grounded conversations about their capabilities and limitations.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Aaron",
   "pi_last_name": "Mueller",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Aaron Mueller",
   "pi_email_addr": "amueller@bu.edu",
   "nsf_id": "000934658",
   "pi_start_date": "2025-08-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Trustees of Boston University",
  "inst_street_address": "1 SILBER WAY",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173534365",
  "inst_zip_code": "022151703",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "TRUSTEES OF BOSTON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "THL6A6JLE1S7"
 },
 "perf_inst": {
  "perf_inst_name": "Trustees of Boston University",
  "perf_str_addr": "1 SILBER WAY",
  "perf_city_name": "BOSTON",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "022151703",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 471529.0
  }
 ],
 "por": null
}