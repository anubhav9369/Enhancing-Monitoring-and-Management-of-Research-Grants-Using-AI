{
 "awd_id": "2433071",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: RI: Small: Evaluation Concepts for Assessing and Improving Large Language Models",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032922972",
 "po_email": "emiltsak@nsf.gov",
 "po_sign_block_name": "Eleni Miltsakaki",
 "awd_eff_date": "2025-07-01",
 "awd_exp_date": "2028-06-30",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "2025-06-25",
 "awd_max_amd_letter_date": "2025-06-25",
 "awd_abstract_narration": "Systems based on modern large language models (LLMs) play an increasing role in how users access information and compose text. For instance, a user executing a web search will increasingly rely on LLM-based systems to summarize their search results, rather than viewing individual web pages, and they might use LLM-based systems to \u201ctalk to\u201d long documents like financial reports, rather than reading them in their entirety. To support these new paradigms, it is important that an LLM be able to generate responses that are factual, informative and safe. However, satisfying these criteria is not sufficient: a response should also be at the right level of abstraction or detail, in the right format, creative where appropriate, and aligned with other user needs. Current practice has neglected evaluation of these more subtle factors. This project proposes to address these shortcomings by identifying a set of \u201cevaluation concepts\u201d to indicate the kinds of areas where LLMs are failing, like \u201clack of detail in a list.\u201d The project will then develop technology for automatically evaluating and improving LLM responses according to these concepts.\r\n\r\nThis project aims to improve the evaluation and the functionality of LLMs in two ways. First, the project will discover a concept taxonomy and learn how to evaluate LLM responses according to the concepts in that taxonomy. This process will necessitate advances in reward models, which are themselves LLMs, customized to reliably score responses. Second, these reward models are applied to actually improve the LLMs\u2019 responses. Specifically, the project will curate training data exhibiting the correct kinds of behavior for each concept, enabling training of LLMs that do better on those concepts. Finally, the project will develop methods for iteratively improving responses using our reward models. The project will open-source the concept taxonomy and reward models that will outperform closed-source, proprietary models. These models will enable the public to have a better sense of the performance of LLM systems across a variety of applications, and will drive the open-source community to build stronger, more reliable LLM systems.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Gregory",
   "pi_last_name": "Durrett",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Gregory C Durrett",
   "pi_email_addr": "gdurrett@cs.utexas.edu",
   "nsf_id": "000737219",
   "pi_start_date": "2025-06-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Austin",
  "inst_street_address": "110 INNER CAMPUS DR",
  "inst_street_address_2": "",
  "inst_city_name": "AUSTIN",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "5124716424",
  "inst_zip_code": "787121139",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT AUSTIN",
  "org_prnt_uei_num": "",
  "org_uei_num": "V6AFQPN18437"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Austin",
  "perf_str_addr": "110 INNER CAMPUS DR",
  "perf_city_name": "AUSTIN",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "787121139",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "TX25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 300000.0
  }
 ],
 "por": null
}