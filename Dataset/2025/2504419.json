{
 "awd_id": "2504419",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: HCC: Medium: Transforming haptic graphical user interfaces by leveraging dynamic behaviors of soft materials",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Thomas Martin",
 "awd_eff_date": "2025-10-01",
 "awd_exp_date": "2028-09-30",
 "tot_intn_awd_amt": 249000.0,
 "awd_amount": 249000.0,
 "awd_min_amd_letter_date": "2025-06-25",
 "awd_max_amd_letter_date": "2025-06-25",
 "awd_abstract_narration": "The human sense of touch is incredibly powerful and vital aspect of human experience. However, touch is still not well studied. The sense of touch allows one to move about, as well as identify, analyze properties of and manipulate objects. Touch complements other senses and is a critical part of a person\u2019s ability to identify fine features, develop spatial awareness, learn, and form memories. Touch enables people to combine information across different senses and to form emotional experiences. However, most digital experiences have yet to include touch. This project will use a novel approach to enable images that combine sight and touch through detailed, dynamic, and rich haptic displays built from recently developed soft materials that significantly respond to changes in their settings. Including rich haptic experiences will transform human-computer interaction, much like the giant leap forward when computers began presenting graphics on screens. Enabling users to \"feel\" digital graphics has the potential to redefine experiences across a wide range of applications, including education, entertainment, and product design.  Haptic interfaces offer access to visual information when users must look elsewhere.  They also introduce interactions the combine touch with other senses to enhance tasks like operating machines from a distance, providing a person with the sense of being present elsewhere, and exploring complex scientific data or medical images.\r\n\r\nA key hurdle that has prevented people from living in this multimedia digital world is the lack of actuation technology specifically designed for tactile haptics, thereby limiting the palette of haptic interactions available to designers. Most work which incorporates tactile haptics in computation use vibration motors, which do not take advantage of the wide range of possible sensations and receptors in people\u2019s skin. This project will make use of the enormous amount of innovation that has occurred in stimuli-responsive soft materials, and create high-resolution, dynamic and rich tactile digital graphical content. The investigators will develop novel tactile haptic technologies for digital illustrations through an iterative process in which haptic perception tests and functional evaluations will inform materials specifications based on three main research objectives: (1) Identify the potential of stimuli-responsive soft materials to create haptic pixels to render black and white graphical information to users through touch. (2) Incorporating dynamic material response into tactile pixels to expand the capabilities of rendered graphical content. (3) Augmenting the richness of graphical content rendered for users through an increase of the dynamic mechanical capabilities of tactile pixels. Through this proposed work, the investigators will bridge the gap between materials, haptics, and human-computer interaction research to create new tactile digital expressions. These advances will enable and accelerate new user interfaces and interactions through this underutilized information channel.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Lynn",
   "pi_last_name": "Walker",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Lynn M Walker",
   "pi_email_addr": "lmwalker@umn.edu",
   "nsf_id": "000086752",
   "pi_start_date": "2025-06-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Minnesota-Twin Cities",
  "inst_street_address": "2221 UNIVERSITY AVE SE STE 100",
  "inst_street_address_2": "",
  "inst_city_name": "MINNEAPOLIS",
  "inst_state_code": "MN",
  "inst_state_name": "Minnesota",
  "inst_phone_num": "6126245599",
  "inst_zip_code": "554143074",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MN05",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MINNESOTA",
  "org_prnt_uei_num": "",
  "org_uei_num": "KABJZBBJ4B54"
 },
 "perf_inst": {
  "perf_inst_name": "University of Minnesota-Twin Cities",
  "perf_str_addr": "200 OAK ST SE",
  "perf_city_name": "MINNEAPOLIS",
  "perf_st_code": "MN",
  "perf_st_name": "Minnesota",
  "perf_zip_code": "554552009",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MN05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 249000.0
  }
 ],
 "por": null
}