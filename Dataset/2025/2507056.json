{
 "awd_id": "2507056",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Multimodal Immersive Training to Develop Expertise in Spatial-Temporal Reasoning for Fire Investigations",
 "cfda_num": "47.070, 47.076",
 "org_code": "11090000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2025-09-01",
 "awd_exp_date": "2028-08-31",
 "tot_intn_awd_amt": 539673.0,
 "awd_amount": 539673.0,
 "awd_min_amd_letter_date": "2025-08-20",
 "awd_max_amd_letter_date": "2025-08-20",
 "awd_abstract_narration": "Fire investigation training programs aim to equip investigators with the skills to identify fire origins and causes, but the chaotic nature of post-fire scenes presents substantial challenges. Investigators must connect evidence and scene features to the fire dynamics that shaped a scene, which requires strong spatial-temporal reasoning skills. Immersive training in realistic environments is essential to help investigators piece together evidence, analyze fire progression, and accurately trace fire origins. However, most training programs in the U.S. rely on lectures and 2D visuals, lacking the immersive experience needed to develop these crucial reasoning skills. Further, many investigators lack formal education in fire science, which is essential for understanding fire behavior. This project seeks to create a multimodal embodied training platform that advances fire investigation training through adaptive deliberate practice and learning analytics, focusing on the spatial-temporal reasoning skills needed to reconstruct fire development from observed fire damage and scene features. This new training approach will improve the quality and effectiveness of fire investigation practices, benefiting public safety by enabling more accurate identification of fire origins and causes. Many of the ideas can be extended to related fields such as crime scene investigation and other STEM areas requiring advanced spatial-temporal reasoning skills. \r\n\r\nTo achieve these goals, the training platform will incorporate an AI-driven, physics-informed 3D fire modeling system that dynamically generates and visualizes fire scenarios based on learner-selected fire origins. Learners will identify and analyze scattered evidence, reconstruct fire progression, test interpretations, and explore variations in fire dynamics relative to observed damage patterns. Multimodal sensors will track learner interactions, enabling adaptive instructional approaches, enhancing engagement, and fostering seamless interactions between learners, instructors, and virtual fire scenarios. A deliberate practice pedagogical model will integrate structured skill-building exercises, multimodal analytics for performance assessment, and personalized adaptive training tailored to individual learner profiles. The platform's effectiveness will be evaluated in three phases: iterative expert reviews, student prototype assessments, and nationwide testing by early-career fire investigators, ensuring robust skill development in spatial-temporal reasoning for fire investigation.\r\n\r\nThis project is funded by the Research on Innovative Technologies for Enhanced Learning (RITEL) program that supports early-stage exploratory research in emerging technologies for teaching and learning.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DRL",
 "org_div_long_name": "Division of Research on Learning in Formal and Informal Settings (DRL)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ruohan",
   "pi_last_name": "Gao",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ruohan Gao",
   "pi_email_addr": "rhgao@umd.edu",
   "nsf_id": "0000A15YD",
   "pi_start_date": "2025-08-20",
   "pi_end_date": null
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Shuna",
   "pi_last_name": "Ni",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Shuna Ni",
   "pi_email_addr": "shunani@umd.edu",
   "nsf_id": "000867876",
   "pi_start_date": "2025-08-20",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Stanislav",
   "pi_last_name": "Stoliarov",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Stanislav Stoliarov",
   "pi_email_addr": "stolia@umd.edu",
   "nsf_id": "000597249",
   "pi_start_date": "2025-08-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland, College Park",
  "inst_street_address": "3112 LEE BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE PARK",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "3014056269",
  "inst_zip_code": "207425100",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "MD04",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND, COLLEGE PARK",
  "org_prnt_uei_num": "NPU8ULVAAS23",
  "org_uei_num": "NPU8ULVAAS23"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland, College Park",
  "perf_str_addr": "3112 LEE BUILDING",
  "perf_city_name": "COLLEGE PARK",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "207425100",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "MD04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802000",
   "pgm_ele_name": "Cyberlearn & Future Learn Tech"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 539673.0
  }
 ],
 "por": null
}