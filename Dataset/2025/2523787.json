{
 "awd_id": "2523787",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: CISE Crosscutting Small: SCH: Towards Auto-Prompt Textual Annotations Generation with Domain Knowledge for Multimodal Medical Image Segmentation",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032928910",
 "po_email": "jafowler@nsf.gov",
 "po_sign_block_name": "James Fowler",
 "awd_eff_date": "2025-10-01",
 "awd_exp_date": "2028-09-30",
 "tot_intn_awd_amt": 390000.0,
 "awd_amount": 390000.0,
 "awd_min_amd_letter_date": "2025-08-19",
 "awd_max_amd_letter_date": "2025-08-19",
 "awd_abstract_narration": "Medical image segmentation is essential for clinical decision making and disease monitoring, yet current deep-learning approaches are limited by their reliance on imaging data alone and lack of contextual understanding. Vision-language models (VLMs) offer a promising alternative by generating textual annotations, but their dependence on manually crafted prompts and poor adaptation to segmentation tasks constrain their clinical utility. Moreover, these models struggle to generalize across imaging modalities and anatomical regions. This project develops an automated framework that generates segmentation-specific textual descriptions without human-created prompts, improving annotation efficiency and segmentation quality. It further integrates dynamic knowledge-graph reasoning to embed evolving medical expertise into the annotation process, enhancing adaptability across diverse imaging contexts. The approach aims to create robust and generalizable artificial intelligence (AI) tools for real-world clinical use. Broader-impact aspects of the project include the engagement of students through hands-on research, interdisciplinary collaboration, and open-access tools that advance science and education as well as clinical relevance that is ensured through close collaboration with medical experts, allowing the research to address real-world healthcare needs and support translational impact.\r\n\r\nThe project introduces a multimodal framework that leverages the bidirectional relationship between images and text to refine segmentation. Key components include: (1) an auto-prompting mechanism driven by graph-based reasoning to produce task-specific textual descriptions; (2) a knowledge-graph module that encodes and updates domain expertise to improve generalization; (3) a multi-level feature-alignment strategy with asynchronous fusion and bidirectional encoding to enhance multimodal learning; and (4) a closed-loop learning paradigm wherein segmentation and annotation mutually refine each other. Together, these components establish a comprehensive system for automated and adaptive medical image segmentation with high clinical relevance.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Haoteng",
   "pi_last_name": "Tang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Haoteng Tang",
   "pi_email_addr": "haoteng.tang@utrgv.edu",
   "nsf_id": "000953208",
   "pi_start_date": "2025-08-19",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Pengfei",
   "pi_last_name": "Gu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Pengfei Gu",
   "pi_email_addr": "pengfei.gu01@utrgv.edu",
   "nsf_id": "0000A2MKM",
   "pi_start_date": "2025-08-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "The University of Texas Rio Grande Valley",
  "inst_street_address": "1201 W UNIVERSITY DR",
  "inst_street_address_2": "",
  "inst_city_name": "EDINBURG",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9566652889",
  "inst_zip_code": "785392909",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "TX15",
  "org_lgl_bus_name": "THE UNIVERSITY OF TEXAS RIO GRANDE VALLEY",
  "org_prnt_uei_num": "",
  "org_uei_num": "L3ATVUT2KNK7"
 },
 "perf_inst": {
  "perf_inst_name": "The University of Texas Rio Grande Valley",
  "perf_str_addr": "1201 W UNIVERSITY DR",
  "perf_city_name": "EDINBURG",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "785392909",
  "perf_ctry_code": "US",
  "perf_cong_dist": "15",
  "perf_st_cong_dist": "TX15",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "079Z",
   "pgm_ref_txt": "Machine Learning Theory"
  },
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 390000.0
  }
 ],
 "por": null
}