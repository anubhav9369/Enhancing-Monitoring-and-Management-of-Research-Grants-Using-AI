{
 "awd_id": "2442716",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Robust Machine Learning via Principled Defenses against Adversaries and Distribution Shifts",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032922972",
 "po_email": "emiltsak@nsf.gov",
 "po_sign_block_name": "Eleni Miltsakaki",
 "awd_eff_date": "2025-08-01",
 "awd_exp_date": "2030-07-31",
 "tot_intn_awd_amt": 508043.0,
 "awd_amount": 431250.0,
 "awd_min_amd_letter_date": "2025-07-16",
 "awd_max_amd_letter_date": "2025-07-16",
 "awd_abstract_narration": "Machine learning (ML) systems have achieved impressive capabilities across domains such as vision, language, and planning. However, even state-of-the-art models can fail dramatically in unpredictable ways, including under minor shifts in data distribution. These failures are exacerbated in the presence of adversaries (i.e., other actors or systems that attempt to undermine or attack the ML system) These vulnerabilities present serious concerns for deploying ML in high-stakes settings. This project aims to develop principled defenses that make robustness a core design property of ML systems rather than an afterthought. The approach is to bridge rigorous analysis with practical experimentation in order to understand, predict, and ultimately fix brittleness in modern models. Through new algorithmic tools and conceptual insights, this work will lead to the development of reliable and trustworthy AI systems that can operate safely and reliably in complex, real-world environments.\r\n\r\nThis project will establish a framework of robustness via analysis for building machine learning systems. This approach interleaves simplified theoretical models with real-world experiments to derive actionable insights that improve robustness in practice. The project proceeds along three technical thrusts. First, it develops robust finetuning techniques for large pretrained models (foundation models) by minimizing forgetting and preserving generalization across domains. Second, it introduces defenses against adversarial attacks on language models, including novel finetuning paradigms that enable models to robustly self-correct and consistently enforce safety guidelines, even under complex and varied jailbreak scenarios (malicious attempts to trick the system into generating undesirable output). Third, the project studies robustness in autonomous AI agents composed of multiple subsystems, identifying weakest links, developing methods to enforce trust hierarchies (i.e. what can be trusted and when), and introducing mechanisms to provide formal safety guarantees across the system. Together, these efforts aim to shift the foundations of robust ML from heuristic patchwork to theoretically informed, systematically validated design.\r\n\r\nThis award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Aditi",
   "pi_last_name": "Raghunathan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Aditi Raghunathan",
   "pi_email_addr": "raditi@cmu.edu",
   "nsf_id": "000918639",
   "pi_start_date": "2025-07-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133890",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "5000 FORBES AVE",
  "perf_city_name": "PITTSBURGH",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002526DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002930DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2025,
   "fund_oblg_amt": 431250.0
  }
 ],
 "por": null
}